{"metadata":{"orig_nbformat":4,"interpreter":{"hash":"75cd0ae9ecbec3ab72299e27db8b610059db44a2f7a4c5d8b808971e07cf7af1"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Лабораторна робота 6\n### Студента групи МІТ-31 (підгрупа 2)\n### Шило Івана Костянтиновича\n## Завдання\n\n1. Виконати вирішення задач класифікації для 3 класів з набору даних food101\n2. Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n - номер за списком (обчислені значення індексів вказані у даному документі у стовпчиках D:F) )\n3. Отримані результати викласти на github у репозиторій ml2021 в основну (default) гілку в папці Lab6.","metadata":{}},{"cell_type":"raw","source":"%pip install tensorflow","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nimport pathlib\nimport numpy as np\nimport pandas as pd\nimport zipfile\nimport os","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Unzip file\nzip_ref = zipfile.ZipFile(\"small.zip\", \"r\")\nzip_ref.extractall()\nzip_ref.close()","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"main_dir=\"small\"","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"for dirpath, dirnames, filenames in os.walk(main_dir):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"There are 3 directories and 0 images in 'small'.\nThere are 3 directories and 0 images in 'small/test'.\nThere are 0 directories and 250 images in 'small/test/gnocchi'.\nThere are 0 directories and 250 images in 'small/test/pork_chop'.\nThere are 0 directories and 250 images in 'small/test/cheesecake'.\nThere are 1 directories and 1 images in 'small/__MACOSX'.\nThere are 1 directories and 2 images in 'small/__MACOSX/101_food_classes_10_percent'.\nThere are 0 directories and 34 images in 'small/__MACOSX/101_food_classes_10_percent/test'.\nThere are 3 directories and 0 images in 'small/train'.\nThere are 0 directories and 75 images in 'small/train/gnocchi'.\nThere are 0 directories and 75 images in 'small/train/pork_chop'.\nThere are 0 directories and 75 images in 'small/train/cheesecake'.\n","output_type":"stream"}]},{"cell_type":"code","source":"data_dir = pathlib.Path(\"small/train/\") # turn our training path into a Python path\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\nprint(class_names)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['cheesecake' 'gnocchi' 'pork_chop']\n","output_type":"stream"}]},{"cell_type":"raw","source":"#Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 \n# (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних,\n# n - номер за списком (обчислені значення індексів вказані у даному документі у стовпчиках D:F))\n\nn = 19\n\nl = []\narr = (n - 1, n + 29, (n + 59) % 100)\nfor i in range(len(class_names)):\n    if i in arr:\n        l.append(class_names[i])\n\nprint(l)","metadata":{}},{"cell_type":"raw","source":"l = []\nfor i in range(len(class_names)):\n        l.append(class_names[i])\nl.append(class_names)\nprint(l)","metadata":{}},{"cell_type":"code","source":"def view_random_image(target_dir, target_class):\n      # Setup target directory (we'll view images from here)\n  target_folder = target_dir+target_class\n\n  # Get a random image path\n  random_image = random.sample(os.listdir(target_folder), 1)\n\n  # Read in the image and plot it using matplotlib\n  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n  plt.imshow(img)\n  plt.title(target_class)\n  plt.axis(\"off\");\n\n  print(f\"Image shape: {img.shape}\") # show the shape of the image\n\n  return img\n\n  # View a random image from the training dataset\nimg = view_random_image(target_dir=\"small/train/\",\n                        target_class=\"cheesecake\")","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Image shape: (512, 512, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"img","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([[[203, 190, 208],\n        [205, 194, 211],\n        [205, 194, 210],\n        ...,\n        [  6,   8,  29],\n        [  5,  10,  30],\n        [  8,  13,  33]],\n\n       [[203, 192, 209],\n        [206, 195, 212],\n        [206, 195, 211],\n        ...,\n        [  8,  10,  31],\n        [  8,  10,  31],\n        [  7,  12,  32]],\n\n       [[199, 190, 207],\n        [201, 193, 208],\n        [202, 194, 209],\n        ...,\n        [ 11,  13,  34],\n        [ 10,  12,  33],\n        [  8,  10,  31]],\n\n       ...,\n\n       [[238, 205, 126],\n        [239, 206, 129],\n        [238, 205, 128],\n        ...,\n        [100,  88,  72],\n        [100,  88,  72],\n        [101,  89,  75]],\n\n       [[249, 212, 132],\n        [247, 211, 133],\n        [242, 209, 132],\n        ...,\n        [100,  88,  72],\n        [ 99,  87,  71],\n        [ 99,  87,  73]],\n\n       [[247, 210, 130],\n        [248, 211, 131],\n        [244, 208, 130],\n        ...,\n        [100,  88,  72],\n        [ 99,  87,  73],\n        [100,  88,  74]]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"img/255.","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([[[0.79607843, 0.74509804, 0.81568627],\n        [0.80392157, 0.76078431, 0.82745098],\n        [0.80392157, 0.76078431, 0.82352941],\n        ...,\n        [0.02352941, 0.03137255, 0.11372549],\n        [0.01960784, 0.03921569, 0.11764706],\n        [0.03137255, 0.05098039, 0.12941176]],\n\n       [[0.79607843, 0.75294118, 0.81960784],\n        [0.80784314, 0.76470588, 0.83137255],\n        [0.80784314, 0.76470588, 0.82745098],\n        ...,\n        [0.03137255, 0.03921569, 0.12156863],\n        [0.03137255, 0.03921569, 0.12156863],\n        [0.02745098, 0.04705882, 0.1254902 ]],\n\n       [[0.78039216, 0.74509804, 0.81176471],\n        [0.78823529, 0.75686275, 0.81568627],\n        [0.79215686, 0.76078431, 0.81960784],\n        ...,\n        [0.04313725, 0.05098039, 0.13333333],\n        [0.03921569, 0.04705882, 0.12941176],\n        [0.03137255, 0.03921569, 0.12156863]],\n\n       ...,\n\n       [[0.93333333, 0.80392157, 0.49411765],\n        [0.9372549 , 0.80784314, 0.50588235],\n        [0.93333333, 0.80392157, 0.50196078],\n        ...,\n        [0.39215686, 0.34509804, 0.28235294],\n        [0.39215686, 0.34509804, 0.28235294],\n        [0.39607843, 0.34901961, 0.29411765]],\n\n       [[0.97647059, 0.83137255, 0.51764706],\n        [0.96862745, 0.82745098, 0.52156863],\n        [0.94901961, 0.81960784, 0.51764706],\n        ...,\n        [0.39215686, 0.34509804, 0.28235294],\n        [0.38823529, 0.34117647, 0.27843137],\n        [0.38823529, 0.34117647, 0.28627451]],\n\n       [[0.96862745, 0.82352941, 0.50980392],\n        [0.97254902, 0.82745098, 0.51372549],\n        [0.95686275, 0.81568627, 0.50980392],\n        ...,\n        [0.39215686, 0.34509804, 0.28235294],\n        [0.38823529, 0.34117647, 0.28627451],\n        [0.39215686, 0.34509804, 0.29019608]]])"},"metadata":{}}]},{"cell_type":"code","source":"# Set the seed\ntf.random.set_random_seed(42)\n\n# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\n# Setup the train and test directories\ntrain_dir = main_dir+\"/train/\"\ntest_dir = main_dir+\"/test/\"\n\n# Import data from directories and turn it into batches\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                               batch_size=32, # number of images to process at a time \n                                               target_size=(224, 224), # convert all images to be 224 x 224\n                                               class_mode=\"sparse\", # type of problem we're working on\n                                               seed=42)\n\nvalid_data = valid_datagen.flow_from_directory(test_dir,\n                                               batch_size=32,\n                                               target_size=(224, 224),\n                                               class_mode=\"sparse\",\n                                               seed=42)\n\n\n\nmodel_1 = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(filters=10, \n                         kernel_size=3, # can also be (3, 3)\n                         activation=\"relu\", \n                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n                            padding=\"valid\"), # padding can also be 'same'\n  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n  tf.keras.layers.MaxPool2D(2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(1, activation=\"softmax\")\n])\n\n# Compile the model\nmodel_1.compile(loss=\"binary_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])\n\n# Fit the model\nhistory_1 = model_1.fit(train_data,\n                        epochs=2,\n                        steps_per_epoch=len(train_data),\n                        validation_data=valid_data,\n                        validation_steps=len(valid_data))","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 225 images belonging to 3 classes.\nFound 750 images belonging to 3 classes.\nWARNING:tensorflow:From /srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/2\n24/24 [==============================] - 101s 4s/step - loss: 0.1334 - acc: 0.3333\n8/8 [==============================] - 159s 20s/step - loss: -1.3521e-09 - acc: 0.3333 - val_loss: 0.1334 - val_acc: 0.3333\nEpoch 2/2\n24/24 [==============================] - 102s 4s/step - loss: 0.0267 - acc: 0.3333\n8/8 [==============================] - 162s 20s/step - loss: -1.7160 - acc: 0.3333 - val_loss: 0.0267 - val_acc: 0.3333\n","output_type":"stream"}]},{"cell_type":"code","source":"model_1.summary()","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 222, 222, 10)      280       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 220, 220, 10)      910       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 110, 110, 10)      0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 108, 108, 10)      910       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 106, 106, 10)      910       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 53, 53, 10)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 28090)             0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 28091     \n=================================================================\nTotal params: 31,101\nTrainable params: 31,101\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(history_1.history).plot(xlabel=\"epochs\", \nylabel=\"loss\",title=\"History ins_model\", xlim=(0,1))","metadata":{"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7fd4bb546c10>"},"metadata":{}}]},{"cell_type":"code","source":"def plot_loss_curves(history_1):\n    \"\"\"\n    Returns separate loss curves for training and validation metrics.\n    \"\"\" \n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n\n    epochs = range(len(history.history['loss']))\n\n    # Plot loss\n    plt.plot(epochs, loss, label='training_loss')\n    plt.plot(epochs, val_loss, label='val_loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n\n    # Plot accuracy\n    plt.figure()\n    plt.plot(epochs, accuracy, label='training_accuracy')\n    plt.plot(epochs, val_accuracy, label='val_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend();","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history_1)","metadata":{"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-39c1cbd34872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-38a8f40b9f67>\u001b[0m in \u001b[0;36mplot_loss_curves\u001b[0;34m(history_1)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mseparate\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mcurves\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\" \n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model_1.save('model.h5')","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}